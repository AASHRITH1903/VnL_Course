{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3-P6DUw6wL-",
    "outputId": "4bcf437a-3c01-41a7-a58f-eda3f6d2b2ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EgBMWpS-6wJX",
    "outputId": "32c15390-8e28-47c3-c8e9-c1487704c1aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/VisualQuestionAnswering\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/VisualQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BVgJBxmL6wHD",
    "outputId": "b5afea4f-a7f7-48a0-9211-a294b59e5096"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mconfig\u001b[0m/  \u001b[01;34mdataHm4\u001b[0m/  dataHm4.zip  main.ipynb  \u001b[01;34m__pycache__\u001b[0m/  requirements.txt  \u001b[01;34mscratch\u001b[0m/  \u001b[01;34msrc\u001b[0m/  todo.py\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rnigIW9h7cQn"
   },
   "outputs": [],
   "source": [
    "# from zipfile import ZipFile\n",
    "\n",
    "# with ZipFile('dataHm4.zip', 'r') as z:\n",
    "\n",
    "#     z.extractall(path='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "EDoPsGB56swU"
   },
   "outputs": [],
   "source": [
    "# ! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "W-dYBD3PI-Yh"
   },
   "outputs": [],
   "source": [
    "# !unzip -u dataHm4.zip -d ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rzvX4r_z6swV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.dataset import VQADataset, VQABatchSampler\n",
    "from src.train import train_model, test_model\n",
    "from todo import VQAModel\n",
    "from src.scheduler import CustomReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FNSHp3Eb6swW"
   },
   "outputs": [],
   "source": [
    "def load_datasets(config, phases):\n",
    "    config = config['data']\n",
    "    if 'preprocess' in config and config['preprocess']:\n",
    "        print('Preprocessing datasets')\n",
    "        preprocess(\n",
    "            data_dir=config['dir'],\n",
    "            train_ques_file=config['train']['ques'],\n",
    "            train_ans_file=config['train']['ans'],\n",
    "            val_ques_file=config['val']['ques'],\n",
    "            val_ans_file=config['val']['ans'])\n",
    "\n",
    "    print('Loading preprocessed datasets')\n",
    "    datafiles = {x: '{}.pkl'.format(x) for x in phases}\n",
    "    raw_images = not ('preprocess' in config['images'] and config['images']['preprocess'])\n",
    "    if raw_images:\n",
    "        img_dir = {x: config[x]['img_dir'] for x in phases}\n",
    "    else:\n",
    "        img_dir = {x: config[x]['emb_dir'] for x in phases}\n",
    "    datasets = {x: VQADataset(data_dir=config['dir'], qafile=datafiles[x], img_dir=img_dir[x], phase=x,\n",
    "                              img_scale=config['images']['scale'], img_crop=config['images']['crop'], raw_images=raw_images) for x in phases}\n",
    "    batch_samplers = {x: VQABatchSampler(\n",
    "        datasets[x], config[x]['batch_size']) for x in phases}\n",
    "\n",
    "    dataloaders = {x: DataLoader(\n",
    "        datasets[x], batch_sampler=batch_samplers[x], num_workers=config['loader']['workers']) for x in phases}\n",
    "    dataset_sizes = {x: len(datasets[x]) for x in phases}\n",
    "    print(dataset_sizes)\n",
    "    print(\"ques vocab size: {}\".format(len(VQADataset.ques_vocab)))\n",
    "    print(\"ans vocab size: {}\".format(len(VQADataset.ans_vocab)))\n",
    "    return dataloaders, VQADataset.ques_vocab, VQADataset.ans_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZjyZsfQg6swX",
    "outputId": "8488f03b-48f4-4083-a7d3-d60c667e8e31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 53220, 'val': 21303}\n",
      "ques vocab size: 10516\n",
      "ans vocab size: 1001\n",
      "VQAModel(\n",
      "  (image_encoder): ImageEmbedding(\n",
      "    (extractor): VGG(\n",
      "      (features): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (8): ReLU(inplace=True)\n",
      "        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (11): ReLU(inplace=True)\n",
      "        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (13): ReLU(inplace=True)\n",
      "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (15): ReLU(inplace=True)\n",
      "        (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (18): ReLU(inplace=True)\n",
      "        (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (20): ReLU(inplace=True)\n",
      "        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (22): ReLU(inplace=True)\n",
      "        (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (25): ReLU(inplace=True)\n",
      "        (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (27): ReLU(inplace=True)\n",
      "        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (29): ReLU(inplace=True)\n",
      "        (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "      (classifier): Sequential(\n",
      "        (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "        (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "        (5): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (fflayer): Sequential(\n",
      "      (0): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (word_embeddings): Embedding(10516, 300)\n",
      "  (question_encoder): QuesEmbedding(\n",
      "    (lstm): LSTM(300, 512, bidirectional=True)\n",
      "    (fflayer): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fusion_module): Fusion(\n",
      "    (image_transformation_layers): ModuleList(\n",
      "      (0-4): 5 x Sequential(\n",
      "        (0): Dropout(p=0.5, inplace=False)\n",
      "        (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (ques_transformation_layers): ModuleList(\n",
      "      (0-4): 5 x Sequential(\n",
      "        (0): Dropout(p=0.5, inplace=False)\n",
      "        (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "config mode  train\n"
     ]
    }
   ],
   "source": [
    "config = yaml.safe_load(open(\"config/config_vqa_sgd.yml\"))\n",
    "config['use_gpu'] = config['use_gpu'] and torch.cuda.is_available()\n",
    "torch.manual_seed(config['seed'])\n",
    "torch.cuda.manual_seed(config['seed'])\n",
    "\n",
    "if config['mode'] == 'test':\n",
    "    phases = ['train', 'test']\n",
    "else:\n",
    "    phases = ['train', 'val']\n",
    "dataloaders, ques_vocab, ans_vocab = load_datasets(config, phases)\n",
    "\n",
    "# add model parameters to config\n",
    "config['model']['params']['vocab_size'] = len(ques_vocab)\n",
    "config['model']['params']['output_size'] = len(ans_vocab) - 1   # -1 as don't want model to predict '<unk>'\n",
    "config['model']['params']['extract_img_features'] = 'preprocess' in config['data']['images'] and config['data']['images']['preprocess']\n",
    "# which features dir? test, train or validate?\n",
    "config['model']['params']['features_dir'] = os.path.join(\n",
    "    config['data']['dir'], config['data']['train']['emb_dir'])\n",
    "model = VQAModel(mode=config['mode'], **config['model']['params'])\n",
    "print(model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if config['optim']['class'] == 'sgd':\n",
    "    optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                            **config['optim']['params'])\n",
    "elif config['optim']['class'] == 'rmsprop':\n",
    "    optimizer = optim.RMSprop(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                                **config['optim']['params'])\n",
    "else:\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                            **config['optim']['params'])\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "startEpoch = 0\n",
    "if 'reload' in config['model']:\n",
    "    pathForTrainedModel = os.path.join(config['save_dir'],\n",
    "                                        config['model']['reload'])\n",
    "    if os.path.exists(pathForTrainedModel):\n",
    "        print(\n",
    "            \"=> loading checkpoint/model found at '{0}'\".format(pathForTrainedModel))\n",
    "        checkpoint = torch.load(pathForTrainedModel)\n",
    "        startEpoch = checkpoint['epoch']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        # optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "if config['use_gpu']:\n",
    "    model = model.cuda()\n",
    "\n",
    "print('config mode ', config['mode'])\n",
    "save_dir = os.path.join(os.getcwd(), config['save_dir'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "4LrbLZu6Dk1-",
    "outputId": "a22eeeec-66c0-4703-8218-ac91ff2d4a78"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Epochs : 5'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Epochs : %s' % config['optim']['n_epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FT3XGnFz6swY",
    "outputId": "b6105826-f3d8-46fd-8059-be71db280ff4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomReduceLROnPlateau\n",
      "begin training\n",
      "Training Model with use_gpu=True...\n",
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1383/53220) - running loss: 0.2445401924723572, running_corrects: 237, example_count: 1383, acc: 17.136659436008678\n",
      "(2724/53220) - running loss: 0.23871917539056003, running_corrects: 513, example_count: 2724, acc: 18.83259911894273\n",
      "(4139/53220) - running loss: 0.21601595121698408, running_corrects: 818, example_count: 4139, acc: 19.763227832809857\n",
      "(5557/53220) - running loss: 0.19934954427870483, running_corrects: 1104, example_count: 5557, acc: 19.86683462299802\n",
      "(6978/53220) - running loss: 0.18718141483078374, running_corrects: 1416, example_count: 6978, acc: 20.292347377472055\n",
      "(8386/53220) - running loss: 0.17653144835970894, running_corrects: 1766, example_count: 8386, acc: 21.05890770331505\n",
      "(9800/53220) - running loss: 0.16802616691102787, running_corrects: 2128, example_count: 9800, acc: 21.714285714285715\n",
      "(11224/53220) - running loss: 0.16092900681181288, running_corrects: 2513, example_count: 11224, acc: 22.38952245188881\n",
      "(12642/53220) - running loss: 0.1558572477393655, running_corrects: 2894, example_count: 12642, acc: 22.891947476665084\n",
      "(14035/53220) - running loss: 0.15152758853818582, running_corrects: 3311, example_count: 14035, acc: 23.591022443890274\n",
      "(15428/53220) - running loss: 0.14871200651803534, running_corrects: 3657, example_count: 15428, acc: 23.703655690951518\n",
      "(16850/53220) - running loss: 0.1456350136864433, running_corrects: 4021, example_count: 16850, acc: 23.863501483679524\n",
      "(18239/53220) - running loss: 0.1430219916295009, running_corrects: 4402, example_count: 18239, acc: 24.135095125829267\n",
      "(19679/53220) - running loss: 0.14027989191146115, running_corrects: 4792, example_count: 19679, acc: 24.350830834900147\n",
      "(21073/53220) - running loss: 0.13881322689040104, running_corrects: 5124, example_count: 21073, acc: 24.315474778152137\n",
      "(22484/53220) - running loss: 0.1370587571779406, running_corrects: 5505, example_count: 22484, acc: 24.484077566269345\n",
      "(23884/53220) - running loss: 0.13566420309768412, running_corrects: 5888, example_count: 23884, acc: 24.652487020599565\n",
      "(25261/53220) - running loss: 0.13409944373861654, running_corrects: 6288, example_count: 25261, acc: 24.89212620244646\n",
      "(26697/53220) - running loss: 0.13249376385507636, running_corrects: 6708, example_count: 26697, acc: 25.126418698730195\n",
      "(28082/53220) - running loss: 0.13168586045662806, running_corrects: 7066, example_count: 28082, acc: 25.162025496759487\n",
      "(29457/53220) - running loss: 0.13055057788804134, running_corrects: 7459, example_count: 29457, acc: 25.321655294157587\n",
      "(30832/53220) - running loss: 0.12996519159198922, running_corrects: 7825, example_count: 30832, acc: 25.379475869226773\n",
      "(32257/53220) - running loss: 0.1288665339323445, running_corrects: 8232, example_count: 32257, acc: 25.520042161391327\n",
      "(33691/53220) - running loss: 0.12809135197446728, running_corrects: 8600, example_count: 33691, acc: 25.526104894482206\n",
      "(35113/53220) - running loss: 0.12717868120298972, running_corrects: 9021, example_count: 35113, acc: 25.691339389969524\n",
      "(36514/53220) - running loss: 0.12656806104349178, running_corrects: 9384, example_count: 36514, acc: 25.699731609793503\n",
      "(37945/53220) - running loss: 0.1255758204169857, running_corrects: 9789, example_count: 37945, acc: 25.79786533140071\n",
      "(39351/53220) - running loss: 0.12489558012524099, running_corrects: 10189, example_count: 39351, acc: 25.892607557622423\n",
      "(40769/53220) - running loss: 0.12428141717028415, running_corrects: 10565, example_count: 40769, acc: 25.91429762809978\n",
      "(42143/53220) - running loss: 0.1237978286228117, running_corrects: 10954, example_count: 42143, acc: 25.992454262866904\n",
      "(43546/53220) - running loss: 0.12313835852640988, running_corrects: 11366, example_count: 43546, acc: 26.10113443255408\n",
      "(44934/53220) - running loss: 0.1224586991960929, running_corrects: 11802, example_count: 44934, acc: 26.265188943784217\n",
      "(46347/53220) - running loss: 0.12193735000999582, running_corrects: 12171, example_count: 46347, acc: 26.26059939154638\n",
      "Train Loss: 0.1217 Acc: 23.251 (12374/47024)\n",
      "Epoch Train Time: 8m 9s\n",
      "Validation Loss: 0.1025 Acc: 25.593 (5452/18324)\n",
      "Epoch Validation Time: 5m 49s\n",
      "Num_bad_epochs: 0, unconstrainedBadEpochs: 0, bestMetric: 0.7440736293792725, currentThreshold: 0.729192156791687\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:1350: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1420/53220) - running loss: 0.09764204167983902, running_corrects: 437, example_count: 1420, acc: 30.77464788732394\n",
      "(2823/53220) - running loss: 0.09991021714563535, running_corrects: 853, example_count: 2823, acc: 30.216082182075805\n",
      "(4205/53220) - running loss: 0.10032382266558308, running_corrects: 1276, example_count: 4205, acc: 30.344827586206897\n",
      "(5571/53220) - running loss: 0.10353816700375416, running_corrects: 1627, example_count: 5571, acc: 29.204810626458443\n",
      "(6979/53220) - running loss: 0.10401736721471176, running_corrects: 2013, example_count: 6979, acc: 28.843673878779196\n",
      "(8404/53220) - running loss: 0.10249819552994864, running_corrects: 2458, example_count: 8404, acc: 29.247977153736315\n",
      "(9821/53220) - running loss: 0.1019638189047396, running_corrects: 2886, example_count: 9821, acc: 29.38600957132675\n",
      "(11240/53220) - running loss: 0.10133130146303211, running_corrects: 3317, example_count: 11240, acc: 29.51067615658363\n",
      "(12646/53220) - running loss: 0.10022617596617402, running_corrects: 3772, example_count: 12646, acc: 29.82761347461648\n",
      "(14032/53220) - running loss: 0.10005580217438402, running_corrects: 4216, example_count: 14032, acc: 30.045610034207527\n",
      "(15429/53220) - running loss: 0.10023549956717628, running_corrects: 4616, example_count: 15429, acc: 29.917687471644307\n",
      "(16824/53220) - running loss: 0.10021941695996497, running_corrects: 5035, example_count: 16824, acc: 29.927484545886827\n",
      "(18233/53220) - running loss: 0.09955997491893992, running_corrects: 5512, example_count: 18233, acc: 30.23090001645368\n",
      "(19612/53220) - running loss: 0.099648116261311, running_corrects: 5901, example_count: 19612, acc: 30.08872119110749\n",
      "(21029/53220) - running loss: 0.09961369938975173, running_corrects: 6311, example_count: 21029, acc: 30.010937277093536\n",
      "(22450/53220) - running loss: 0.09953788575622977, running_corrects: 6736, example_count: 22450, acc: 30.00445434298441\n",
      "(23846/53220) - running loss: 0.09942046609355441, running_corrects: 7178, example_count: 23846, acc: 30.101484525706617\n",
      "(25255/53220) - running loss: 0.09889038888664912, running_corrects: 7635, example_count: 25255, acc: 30.231637299544644\n",
      "(26654/53220) - running loss: 0.09872825416043281, running_corrects: 8055, example_count: 26654, acc: 30.220604787273952\n",
      "(28064/53220) - running loss: 0.09830874438183074, running_corrects: 8528, example_count: 28064, acc: 30.387685290763965\n",
      "(29447/53220) - running loss: 0.0980445816966173, running_corrects: 8962, example_count: 29447, acc: 30.434339661086018\n",
      "(30857/53220) - running loss: 0.0978912313102316, running_corrects: 9398, example_count: 30857, acc: 30.456622484363354\n",
      "(32286/53220) - running loss: 0.09747090275825558, running_corrects: 9863, example_count: 32286, acc: 30.548844700489376\n",
      "(33698/53220) - running loss: 0.09728850790804851, running_corrects: 10329, example_count: 33698, acc: 30.651670722298057\n",
      "(35097/53220) - running loss: 0.09712745529212147, running_corrects: 10773, example_count: 35097, acc: 30.69493119070006\n",
      "(36498/53220) - running loss: 0.09716388548827085, running_corrects: 11185, example_count: 36498, acc: 30.645514822730014\n",
      "(37935/53220) - running loss: 0.09669068105174129, running_corrects: 11650, example_count: 37935, acc: 30.71042572821932\n",
      "(39344/53220) - running loss: 0.09649318874873836, running_corrects: 12087, example_count: 39344, acc: 30.721329808865395\n",
      "(40786/53220) - running loss: 0.09601132562508685, running_corrects: 12563, example_count: 40786, acc: 30.802236061393618\n",
      "(42209/53220) - running loss: 0.09580488799438568, running_corrects: 13037, example_count: 42209, acc: 30.886777701438085\n",
      "(43594/53220) - running loss: 0.0957188916175528, running_corrects: 13503, example_count: 43594, acc: 30.974446024682294\n",
      "(45013/53220) - running loss: 0.09555054054243861, running_corrects: 13967, example_count: 45013, acc: 31.028813898207186\n",
      "(46390/53220) - running loss: 0.09559002957256814, running_corrects: 14393, example_count: 46390, acc: 31.02608320758784\n",
      "Train Loss: 0.0956 Acc: 27.403 (14584/47024)\n",
      "Epoch Train Time: 8m 23s\n",
      "Validation Loss: 0.0909 Acc: 27.419 (5841/18324)\n",
      "Epoch Validation Time: 3m 12s\n",
      "Num_bad_epochs: 0, unconstrainedBadEpochs: 0, bestMetric: 0.7258132696151733, currentThreshold: 0.7112970042228699\n",
      "Epoch 2/4\n",
      "----------\n",
      "(1433/53220) - running loss: 0.08711459315580167, running_corrects: 461, example_count: 1433, acc: 32.17027215631542\n",
      "(2840/53220) - running loss: 0.08806047372415032, running_corrects: 903, example_count: 2840, acc: 31.795774647887328\n",
      "(4287/53220) - running loss: 0.08630488556749981, running_corrects: 1387, example_count: 4287, acc: 32.353627245159785\n",
      "(5673/53220) - running loss: 0.08594994290299922, running_corrects: 1871, example_count: 5673, acc: 32.9807861801516\n",
      "(7066/53220) - running loss: 0.08596202025088244, running_corrects: 2342, example_count: 7066, acc: 33.14463628644212\n",
      "(8475/53220) - running loss: 0.08560839340750095, running_corrects: 2820, example_count: 8475, acc: 33.27433628318584\n",
      "(9840/53220) - running loss: 0.08554688810817594, running_corrects: 3292, example_count: 9840, acc: 33.45528455284553\n",
      "(11233/53220) - running loss: 0.08547895326965015, running_corrects: 3758, example_count: 11233, acc: 33.454998664648805\n",
      "(12623/53220) - running loss: 0.08554773835743756, running_corrects: 4215, example_count: 12623, acc: 33.391428345084364\n",
      "(14046/53220) - running loss: 0.08558659548096112, running_corrects: 4684, example_count: 14046, acc: 33.347572262565855\n",
      "(15441/53220) - running loss: 0.08580555369080244, running_corrects: 5126, example_count: 15441, acc: 33.19733177902985\n",
      "(16835/53220) - running loss: 0.08568812282991084, running_corrects: 5594, example_count: 16835, acc: 33.22839322839323\n",
      "(18226/53220) - running loss: 0.0857035916375889, running_corrects: 6087, example_count: 18226, acc: 33.39734445297926\n",
      "(19639/53220) - running loss: 0.08565011187273262, running_corrects: 6547, example_count: 19639, acc: 33.336727939304446\n",
      "(21037/53220) - running loss: 0.08551881706816063, running_corrects: 7049, example_count: 21037, acc: 33.507629414840515\n",
      "(22429/53220) - running loss: 0.08588481807768268, running_corrects: 7468, example_count: 22429, acc: 33.29617905390343\n",
      "(23825/53220) - running loss: 0.085982531880782, running_corrects: 7967, example_count: 23825, acc: 33.43966421825813\n",
      "(25244/53220) - running loss: 0.08579814905335269, running_corrects: 8464, example_count: 25244, acc: 33.52875930914277\n",
      "(26653/53220) - running loss: 0.08606551437580451, running_corrects: 8931, example_count: 26653, acc: 33.50842306682175\n",
      "(28055/53220) - running loss: 0.08585945467163038, running_corrects: 9450, example_count: 28055, acc: 33.68383532347175\n",
      "(29472/53220) - running loss: 0.0854152567276628, running_corrects: 9973, example_count: 29472, acc: 33.838897937024974\n",
      "(30890/53220) - running loss: 0.08539668568715998, running_corrects: 10464, example_count: 30890, acc: 33.87504046617028\n",
      "(32304/53220) - running loss: 0.08540893412610759, running_corrects: 10902, example_count: 32304, acc: 33.7481426448737\n",
      "(33695/53220) - running loss: 0.08540690806454554, running_corrects: 11376, example_count: 33695, acc: 33.761685710046\n",
      "(35090/53220) - running loss: 0.08528205626611018, running_corrects: 11859, example_count: 35090, acc: 33.7959532630379\n",
      "(36510/53220) - running loss: 0.08517734287018418, running_corrects: 12390, example_count: 36510, acc: 33.935907970419066\n",
      "(37934/53220) - running loss: 0.08503356462303968, running_corrects: 12860, example_count: 37934, acc: 33.90098592291875\n",
      "(39374/53220) - running loss: 0.0847899948690559, running_corrects: 13368, example_count: 39374, acc: 33.95133844669071\n",
      "(40784/53220) - running loss: 0.08486666815010513, running_corrects: 13831, example_count: 40784, acc: 33.912808944684194\n",
      "(42163/53220) - running loss: 0.08487886276736764, running_corrects: 14327, example_count: 42163, acc: 33.98002988402153\n",
      "(43556/53220) - running loss: 0.08482361888580195, running_corrects: 14791, example_count: 43556, acc: 33.958582055285156\n",
      "(44936/53220) - running loss: 0.08502517590269072, running_corrects: 15246, example_count: 44936, acc: 33.92825351611181\n",
      "(46332/53220) - running loss: 0.0849917860769059, running_corrects: 15720, example_count: 46332, acc: 33.92903392903393\n",
      "Train Loss: 0.0850 Acc: 29.998 (15965/47024)\n",
      "Epoch Train Time: 8m 23s\n",
      "Validation Loss: 0.0855 Acc: 29.141 (6208/18324)\n",
      "Epoch Validation Time: 3m 12s\n",
      "Num_bad_epochs: 0, unconstrainedBadEpochs: 0, bestMetric: 0.7085856199264526, currentThreshold: 0.6944139075279235\n",
      "Epoch 3/4\n",
      "----------\n",
      "(1375/53220) - running loss: 0.08713893378864634, running_corrects: 451, example_count: 1375, acc: 32.800000000000004\n",
      "(2755/53220) - running loss: 0.08519094397065427, running_corrects: 925, example_count: 2755, acc: 33.57531760435572\n",
      "(4152/53220) - running loss: 0.0844460125718273, running_corrects: 1393, example_count: 4152, acc: 33.55009633911368\n",
      "(5583/53220) - running loss: 0.08323017115578438, running_corrects: 1884, example_count: 5583, acc: 33.74529822675981\n",
      "(6978/53220) - running loss: 0.08271580662895459, running_corrects: 2366, example_count: 6978, acc: 33.906563485239325\n",
      "(8400/53220) - running loss: 0.08200118662345977, running_corrects: 2866, example_count: 8400, acc: 34.11904761904762\n",
      "(9798/53220) - running loss: 0.08191612116486034, running_corrects: 3370, example_count: 9798, acc: 34.39477444376403\n",
      "(11217/53220) - running loss: 0.08129943661100142, running_corrects: 3896, example_count: 11217, acc: 34.7329945618258\n",
      "(12613/53220) - running loss: 0.08133373935415622, running_corrects: 4368, example_count: 12613, acc: 34.63093633552683\n",
      "(14059/53220) - running loss: 0.08045770961467212, running_corrects: 4894, example_count: 14059, acc: 34.8104417099367\n",
      "(15441/53220) - running loss: 0.08061628855538565, running_corrects: 5364, example_count: 15441, acc: 34.738682727802605\n",
      "(16871/53220) - running loss: 0.08059876648111114, running_corrects: 5836, example_count: 16871, acc: 34.59190326595934\n",
      "(18272/53220) - running loss: 0.08012328122052545, running_corrects: 6376, example_count: 18272, acc: 34.89492119089317\n",
      "(19679/53220) - running loss: 0.08035959814118081, running_corrects: 6838, example_count: 19679, acc: 34.74770059454241\n",
      "(21041/53220) - running loss: 0.0802621092668737, running_corrects: 7314, example_count: 21041, acc: 34.76070528967254\n",
      "(22464/53220) - running loss: 0.07989069554381646, running_corrects: 7839, example_count: 22464, acc: 34.89583333333333\n",
      "(23877/53220) - running loss: 0.08001132307127702, running_corrects: 8310, example_count: 23877, acc: 34.803367257193116\n",
      "(25292/53220) - running loss: 0.07976804440362383, running_corrects: 8825, example_count: 25292, acc: 34.892456112604776\n",
      "(26704/53220) - running loss: 0.07969285239264093, running_corrects: 9327, example_count: 26704, acc: 34.92735170760935\n",
      "(28093/53220) - running loss: 0.07993171104559743, running_corrects: 9819, example_count: 28093, acc: 34.951767344178265\n",
      "(29503/53220) - running loss: 0.07977934803788315, running_corrects: 10358, example_count: 29503, acc: 35.10829407178931\n",
      "(30927/53220) - running loss: 0.0798621531886088, running_corrects: 10850, example_count: 30927, acc: 35.08261389724189\n",
      "(32334/53220) - running loss: 0.07964141656842635, running_corrects: 11377, example_count: 32334, acc: 35.185872456238016\n",
      "(33738/53220) - running loss: 0.0797972031946011, running_corrects: 11886, example_count: 33738, acc: 35.230304108127335\n",
      "(35151/53220) - running loss: 0.07956111706329753, running_corrects: 12426, example_count: 35151, acc: 35.35034565161731\n",
      "(36508/53220) - running loss: 0.07960995916333088, running_corrects: 12918, example_count: 36508, acc: 35.38402541908623\n",
      "(37929/53220) - running loss: 0.0795454139599972, running_corrects: 13436, example_count: 37929, acc: 35.42408183711672\n",
      "(39367/53220) - running loss: 0.07936549148400411, running_corrects: 13950, example_count: 39367, acc: 35.43577107729824\n",
      "(40786/53220) - running loss: 0.07907395490755699, running_corrects: 14495, example_count: 40786, acc: 35.539155592605304\n",
      "(42179/53220) - running loss: 0.07907970766895805, running_corrects: 14999, example_count: 42179, acc: 35.560349937172525\n",
      "(43580/53220) - running loss: 0.07895491268996965, running_corrects: 15502, example_count: 43580, acc: 35.5713630105553\n",
      "(44983/53220) - running loss: 0.07888178557400663, running_corrects: 16028, example_count: 44983, acc: 35.631238467865636\n",
      "(46405/53220) - running loss: 0.07878631858036521, running_corrects: 16516, example_count: 46405, acc: 35.590992349962285\n",
      "Train Loss: 0.0788 Acc: 31.458 (16742/47024)\n",
      "Epoch Train Time: 8m 23s\n",
      "Validation Loss: 0.0832 Acc: 30.287 (6452/18324)\n",
      "Epoch Validation Time: 3m 11s\n",
      "Num_bad_epochs: 1, unconstrainedBadEpochs: 1, bestMetric: 0.7085856199264526, currentThreshold: 0.6944139075279235\n",
      "Epoch 4/4\n",
      "----------\n",
      "(1405/53220) - running loss: 0.0782577163384054, running_corrects: 524, example_count: 1405, acc: 37.295373665480426\n",
      "(2809/53220) - running loss: 0.07557896769483899, running_corrects: 1051, example_count: 2809, acc: 37.415450338198646\n",
      "(4189/53220) - running loss: 0.07648918929775053, running_corrects: 1530, example_count: 4189, acc: 36.52423012652184\n",
      "(5632/53220) - running loss: 0.07456302336967466, running_corrects: 2098, example_count: 5632, acc: 37.25142045454545\n",
      "(7056/53220) - running loss: 0.07389179645042841, running_corrects: 2611, example_count: 7056, acc: 37.00396825396825\n",
      "(8483/53220) - running loss: 0.07387905141647647, running_corrects: 3132, example_count: 8483, acc: 36.920900624778966\n",
      "(9877/53220) - running loss: 0.07374245880030784, running_corrects: 3664, example_count: 9877, acc: 37.09628429685127\n",
      "(11280/53220) - running loss: 0.07326752110153226, running_corrects: 4188, example_count: 11280, acc: 37.12765957446808\n",
      "(12700/53220) - running loss: 0.07316063601200974, running_corrects: 4724, example_count: 12700, acc: 37.196850393700785\n",
      "(14103/53220) - running loss: 0.0730791437552346, running_corrects: 5271, example_count: 14103, acc: 37.37502659008722\n",
      "(15492/53220) - running loss: 0.07340193870545911, running_corrects: 5775, example_count: 15492, acc: 37.27730441518203\n",
      "(16900/53220) - running loss: 0.07323616872525074, running_corrects: 6325, example_count: 16900, acc: 37.426035502958584\n",
      "(18300/53220) - running loss: 0.07354649762963988, running_corrects: 6799, example_count: 18300, acc: 37.15300546448088\n",
      "(19735/53220) - running loss: 0.07327042800552004, running_corrects: 7316, example_count: 19735, acc: 37.07119331137573\n",
      "(21129/53220) - running loss: 0.07333616118045407, running_corrects: 7807, example_count: 21129, acc: 36.9492167163614\n",
      "(22533/53220) - running loss: 0.07338639882318412, running_corrects: 8324, example_count: 22533, acc: 36.941374872409355\n",
      "(23927/53220) - running loss: 0.07356798771147434, running_corrects: 8810, example_count: 23927, acc: 36.820328499185024\n",
      "(25337/53220) - running loss: 0.07349898031828092, running_corrects: 9345, example_count: 25337, acc: 36.882819591901175\n",
      "(26736/53220) - running loss: 0.07337212336502126, running_corrects: 9888, example_count: 26736, acc: 36.983842010771994\n",
      "(28111/53220) - running loss: 0.07360520999080737, running_corrects: 10416, example_count: 28111, acc: 37.053110881861194\n",
      "(29493/53220) - running loss: 0.07378477203523834, running_corrects: 10936, example_count: 29493, acc: 37.079985081205706\n",
      "(30876/53220) - running loss: 0.073822060243996, running_corrects: 11433, example_count: 30876, acc: 37.02876020209872\n",
      "(32302/53220) - running loss: 0.07387528823378743, running_corrects: 11961, example_count: 32302, acc: 37.02866695560647\n",
      "(33718/53220) - running loss: 0.07379422989156904, running_corrects: 12497, example_count: 33718, acc: 37.0632896375823\n",
      "(35137/53220) - running loss: 0.07381579172266199, running_corrects: 13010, example_count: 35137, acc: 37.02649628596636\n",
      "(36552/53220) - running loss: 0.07381104884848967, running_corrects: 13548, example_count: 36552, acc: 37.06500328299409\n",
      "(37941/53220) - running loss: 0.07403350244327896, running_corrects: 14042, example_count: 37941, acc: 37.01009462059513\n",
      "(39374/53220) - running loss: 0.07385600498161388, running_corrects: 14602, example_count: 39374, acc: 37.08538629552496\n",
      "(40762/53220) - running loss: 0.07392837326886124, running_corrects: 15112, example_count: 40762, acc: 37.07374515480104\n",
      "(42145/53220) - running loss: 0.07402915940588516, running_corrects: 15611, example_count: 42145, acc: 37.04116739826788\n",
      "(43550/53220) - running loss: 0.07412933134320956, running_corrects: 16135, example_count: 43550, acc: 37.04936854190585\n",
      "(44956/53220) - running loss: 0.07395053431172952, running_corrects: 16692, example_count: 44956, acc: 37.129637868137735\n",
      "(46372/53220) - running loss: 0.07406921112114759, running_corrects: 17228, example_count: 46372, acc: 37.15172949193479\n",
      "Train Loss: 0.0741 Acc: 32.852 (17484/47024)\n",
      "Epoch Train Time: 8m 21s\n",
      "Validation Loss: 0.0813 Acc: 30.324 (6460/18324)\n",
      "Epoch Validation Time: 3m 12s\n",
      "Num_bad_epochs: 2, unconstrainedBadEpochs: 2, bestMetric: 0.7085856199264526, currentThreshold: 0.6944139075279235\n",
      "Training complete in 60m 50s\n",
      "Best val Acc: 30.324368\n"
     ]
    }
   ],
   "source": [
    "if config['mode'] == 'train':\n",
    "    if 'scheduler' in config['optim'] and config['optim']['scheduler'].lower() == 'CustomReduceLROnPlateau'.lower():\n",
    "        print('CustomReduceLROnPlateau')\n",
    "        exp_lr_scheduler = CustomReduceLROnPlateau(\n",
    "            optimizer, config['optim']['scheduler_params']['maxPatienceToStopTraining'], config['optim']['scheduler_params']['base_class_params'])\n",
    "    else:\n",
    "        # Decay LR by a factor of gamma every step_size epochs\n",
    "        print('lr_scheduler.StepLR')\n",
    "        exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "    print(\"begin training\")\n",
    "    model = train_model(model, dataloaders, optimizer, exp_lr_scheduler, save_dir,\n",
    "                        num_epochs=config['optim']['n_epochs'], use_gpu=config['use_gpu'], best_accuracy=best_acc, start_epoch=startEpoch)\n",
    "elif config['mode'] == 'test':\n",
    "    outputfile = os.path.join(save_dir, config['mode'] + \".json\")\n",
    "    test_model(model, dataloaders['test'], VQADataset.ans_vocab,\n",
    "                outputfile, use_gpu=config['use_gpu'])\n",
    "else:\n",
    "    print(\"Invalid config mode %s !!\" % config['mode'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "vnl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
